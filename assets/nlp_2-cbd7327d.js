import"./prism-line-numbers-61c3c0f1.js";import{_ as s,o as t,c as l,F as i,a as e,h as a}from"./index-bc00eb14.js";const n={},o=e("div",{class:"modal fade",id:"lecture_1",tabindex:"-1","aria-labelledby":"exampleModalLabel","aria-hidden":"true"},[e("div",{class:"modal-dialog modal-dialog-centered modal-fullscreen"},[e("div",{class:"modal-content"},[e("div",{class:"modal-header"},[e("h5",{class:"modal-title",id:"exampleModalLabel"},"Cours 1 : Modélisation statistique du langage, vectorisation de texte"),e("div",null,[e("a",{href:"https://github.com/AntoineSimoulin/m2-data-sciences/raw/master/Cours%201%20-%20Mod%C3%A9lisation%20statistique%20du%20langage/Cours_1.pdf",type:"button",class:"btn-download border-0 opacity-50 bg-transparent p-2 m-n2","aria-label":"Download"},[e("i",{class:"fa-solid fa-download"})]),e("button",{type:"button",class:"btn-close","data-bs-dismiss":"modal","aria-label":"Close"})])]),e("div",{class:"modal-body"},[e("iframe",{width:"100%",height:"100%",marginheight:"0",marginwidth:"0",src:"https://simoulin.io/slides/lecture_1/"})])])])],-1),c=e("div",{class:"modal fade",id:"lecture_2",tabindex:"-1","aria-labelledby":"exampleModalLabel","aria-hidden":"true"},[e("div",{class:"modal-dialog modal-dialog-centered modal-fullscreen"},[e("div",{class:"modal-content"},[e("div",{class:"modal-header"},[e("h5",{class:"modal-title",id:"exampleModalLabel"},"Cours 2 : Représentations sémantiques distributionnelles : Embeddings de mots"),e("div",null,[e("a",{href:"https://github.com/AntoineSimoulin/m2-data-sciences/raw/master/Cours%202%20-%20Embeddings/Cours_2.pdf",type:"button",class:"btn-download border-0 opacity-50 bg-transparent p-2 m-n2","aria-label":"Download"},[e("i",{class:"fa-solid fa-download"})]),e("button",{type:"button",class:"btn-close","data-bs-dismiss":"modal","aria-label":"Close"})])]),e("div",{class:"modal-body"},[e("iframe",{width:"100%",height:"100%",marginheight:"0",marginwidth:"0",src:"https://simoulin.io/slides/lecture_2/"})])])])],-1),d=e("div",{class:"modal fade",id:"lecture_3",tabindex:"-1","aria-labelledby":"exampleModalLabel","aria-hidden":"true"},[e("div",{class:"modal-dialog modal-dialog-centered modal-fullscreen"},[e("div",{class:"modal-content"},[e("div",{class:"modal-header"},[e("h5",{class:"modal-title",id:"exampleModalLabel"},"Cours 3 : Modélisation de séquences de mots : modèles de langue. Application à la génération de texte"),e("div",null,[e("a",{href:"https://github.com/AntoineSimoulin/m2-data-sciences/raw/master/Cours%203%20-%20Language%20Models/Cours_3.pdf",type:"button",class:"btn-download border-0 opacity-50 bg-transparent p-2 m-n2","aria-label":"Download"},[e("i",{class:"fa-solid fa-download"})]),e("button",{type:"button",class:"btn-close","data-bs-dismiss":"modal","aria-label":"Close"})])]),e("div",{class:"modal-body"},[e("iframe",{width:"100%",height:"100%",marginheight:"0",marginwidth:"0",src:"https://simoulin.io/slides/lecture_3/"})])])])],-1),r=e("div",{class:"modal fade",id:"lecture_4",tabindex:"-1","aria-labelledby":"exampleModalLabel","aria-hidden":"true"},[e("div",{class:"modal-dialog modal-dialog-centered modal-fullscreen"},[e("div",{class:"modal-content"},[e("div",{class:"modal-header"},[e("h5",{class:"modal-title",id:"exampleModalLabel"},"Cours 4 : Ouverture sur les méthodes de Deep Learning pour le NLP (RNN, Seq2Seq, Attention, Bert) Application au systèmes de Q&A"),e("div",null,[e("a",{href:"https://github.com/AntoineSimoulin/m2-data-sciences/raw/master/Cours%204%20-%20Introduction%20NLP%20%26%20Deep%20Learning/Cours_4.pdf",type:"button",class:"btn-download border-0 opacity-50 bg-transparent p-2 m-n2","aria-label":"Download"},[e("i",{class:"fa-solid fa-download"})]),e("button",{type:"button",class:"btn-close","data-bs-dismiss":"modal","aria-label":"Close"})])]),e("div",{class:"modal-body"},[e("iframe",{width:"100%",height:"100%",marginheight:"0",marginwidth:"0",src:"https://simoulin.io/slides/lecture_4/"})])])])],-1),b=e("section",{class:"pb-0 py-lg-5"},[e("div",{class:"container"},[e("div",{class:"row"},[e("div",{class:"col-lg-12"},[e("div",{class:"card shadow border-0 rounded-2 p-0"},[e("div",{class:"card-header px-4 py-3"},[e("ul",{class:"nav nav-pills nav-tabs-line py-0",id:"course-pills-tab",role:"tablist"},[e("li",{class:"nav-item me-2 me-sm-4",role:"presentation"},[e("button",{class:"nav-link mb-2 mb-md-0 active",id:"course-pills-tab-1","data-bs-toggle":"pill","data-bs-target":"#course-pills-1",type:"button",role:"tab","aria-controls":"course-pills-1","aria-selected":"true"},"Overview")]),e("li",{class:"nav-item me-2 me-sm-4",role:"presentation"},[e("button",{class:"nav-link mb-2 mb-md-0",id:"course-pills-tab-2","data-bs-toggle":"pill","data-bs-target":"#course-pills-2",type:"button",role:"tab","aria-controls":"course-pills-2","aria-selected":"false"},"Curriculum")]),e("li",{class:"nav-item me-2 me-sm-4",role:"presentation"},[e("button",{class:"nav-link mb-2 mb-md-0",id:"course-pills-tab-3","data-bs-toggle":"pill","data-bs-target":"#course-pills-3",type:"button",role:"tab","aria-controls":"course-pills-3","aria-selected":"false"},"Technical requirements")])])]),e("div",{class:"card-body bg-white p-4"},[e("div",{class:"tab-content pt-2",id:"course-pills-tabContent"},[e("div",{class:"tab-pane fade show active",id:"course-pills-1",role:"tabpanel","aria-labelledby":"course-pills-tab-1"},[e("h5",{class:"mb-3"},"Course Description"),e("p",{class:"mb-3"},[a("Welcome to the "),e("strong",null," Master 2 Mathématiques et Informatique pour la Data Science (M2 MIDS) from Paris University.")]),e("p",null,[a("The course is part of the "),e("a",{class:"text-decoration-none text-capitalize",href:"https://m2mids.github.io/m2mids/"},"M2 MIDS"),a(" cursus.")]),e("p",null,"It introduces statistical methods for Natural Language Processing, including text vectorization, word embeddings, and sequence models. In addition, the course includes practical exercises that cover web scraping, regular expressions, and visualization. The labs include common use cases such as text classification or topic mining. Finally, the course gives an overview about open-source tools for nlp such as nlp libraries, intelligibility methods or deep learning frameworks."),e("h5",{class:"mt-4"},"What you’ll learn"),e("ul",{class:"list-group text-capitalize bg-white list-group-borderless mb-3"},[e("li",{class:"list-group-item h6 fw-light d-flex bg-white mb-0"},[e("i",{class:"fas fa-check-circle text-success me-2"}),a("Text vectorization ")]),e("li",{class:"list-group-item h6 fw-light d-flex bg-white mb-0"},[e("i",{class:"fas fa-check-circle text-success me-2"}),a("word embeddings ")]),e("li",{class:"list-group-item h6 fw-light d-flex bg-white mb-0"},[e("i",{class:"fas fa-check-circle text-success me-2"}),a("sequence models ")]),e("li",{class:"list-group-item h6 fw-light d-flex bg-white mb-0"},[e("i",{class:"fas fa-check-circle text-success me-2"}),a("web scraping")]),e("li",{class:"list-group-item h6 fw-light d-flex bg-white mb-0"},[e("i",{class:"fas fa-check-circle text-success me-2"}),a("regular expressions")]),e("li",{class:"list-group-item h6 fw-light d-flex bg-white mb-0"},[e("i",{class:"fas fa-check-circle text-success me-2"}),a("data vizualization for text")]),e("li",{class:"list-group-item h6 fw-light d-flex bg-white mb-0"},[e("i",{class:"fas fa-check-circle text-success me-2"}),a("text classification")]),e("li",{class:"list-group-item h6 fw-light d-flex bg-white mb-0"},[e("i",{class:"fas fa-check-circle text-success me-2"}),a("topic mining")]),e("li",{class:"list-group-item h6 fw-light d-flex bg-white mb-0"},[e("i",{class:"fas fa-check-circle text-success me-2"}),a("open-source tools ")]),e("li",{class:"list-group-item h6 fw-light d-flex bg-white mb-0"},[e("i",{class:"fas fa-check-circle text-success me-2"}),a("NLP libraries")]),e("li",{class:"list-group-item h6 fw-light d-flex bg-white mb-0"},[e("i",{class:"fas fa-check-circle text-success me-2"}),a("intelligibility methods")]),e("li",{class:"list-group-item h6 fw-light d-flex bg-white mb-0"},[e("i",{class:"fas fa-check-circle text-success me-2"}),a("deep learning frameworks")])])]),e("div",{class:"tab-pane fade",id:"course-pills-2",role:"tabpanel","aria-labelledby":"course-pills-tab-2"},[e("div",{class:"accordion accordion-icon accordion-bg-light",id:"accordionExample2"},[e("div",{class:"accordion-item mb-3"},[e("h6",{class:"accordion-header font-base",id:"heading-1"},[e("button",{class:"accordion-button fw-bold collapsed rounded d-sm-flex d-inline-block",type:"button","data-bs-toggle":"collapse","data-bs-target":"#collapse-1","aria-expanded":"false","aria-controls":"collapse-1"}," Cours 1 : Modélisation statistique du langage, vectorisation de texte ")]),e("div",{id:"collapse-1",class:"accordion-collapse collapse","aria-labelledby":"heading-1","data-bs-parent":"#accordionExample2"},[e("div",{class:"accordion-body mt-3"},[e("div",{class:"d-flex justify-content-between align-items-center"},[e("div",{class:"position-relative d-flex align-items-center"},[e("button",{class:"btn btn-danger-soft btn-round btn-sm mb-0 stretched-link position-static","data-bs-toggle":"modal","data-bs-target":"#lecture_1"},[e("i",{class:"fa-solid fa-file-powerpoint me-0"})]),e("span",{class:"d-inline-block text-truncate ms-2 mb-0 h6 fw-light w-100px w-sm-200px w-md-400px"},"Lecture slides")])]),e("hr"),e("div",{class:"d-flex justify-content-between align-items-center"},[e("div",{class:"position-relative d-flex align-items-center"},[e("a",{href:"#",class:"btn btn-danger-soft btn-round btn-sm mb-0 stretched-link position-static"},[e("i",{class:"fas fa-play me-0"})]),e("span",{class:"d-inline-block text-truncate ms-2 mb-0 h6 fw-light w-100px w-sm-200px w-md-400px"},"Lecture replay")])]),e("hr"),e("div",{class:"d-flex justify-content-between align-items-center"},[e("div",{class:"position-relative d-flex align-items-center"},[e("a",{target:"_blank",href:"https://colab.research.google.com/github/AntoineSimoulin/m2-data-sciences/blob/master/Cours%201%20-%20Mod%C3%A9lisation%20statistique%20du%20langage/Fr%C3%A9quences%20des%20mots.ipynb",class:"btn btn-danger-soft btn-round btn-sm mb-0 stretched-link position-static"},[e("i",{class:"fas fa-display me-0"})]),e("span",{class:"d-inline-block text-truncate ms-2 mb-0 h6 fw-light w-100px w-sm-200px w-md-400px"},"Lab materials")])])])])]),e("div",{class:"accordion-item mb-3"},[e("h6",{class:"accordion-header font-base",id:"heading-2"},[e("button",{class:"accordion-button fw-bold collapsed rounded d-sm-flex d-inline-block",type:"button","data-bs-toggle":"collapse","data-bs-target":"#collapse-2","aria-expanded":"false","aria-controls":"collapse-2"}," TP 1 : Classification de textes, modèles BoW ")]),e("div",{id:"collapse-2",class:"accordion-collapse collapse","aria-labelledby":"heading-2","data-bs-parent":"#accordionExample2"},[e("div",{class:"accordion-body mt-3"},[e("div",{class:"d-flex justify-content-between align-items-center"},[e("div",{class:"position-relative d-flex align-items-center"},[e("a",{target:"_blank",href:"https://colab.research.google.com/github/AntoineSimoulin/m2-data-sciences/blob/master/TP1%20-%20Apprentissage%20supervis%C3%A9%20pour%20le%20NLP/Classification.ipynb",class:"btn btn-danger-soft btn-round btn-sm mb-0 stretched-link position-static"},[e("i",{class:"fas fa-display me-0"})]),e("span",{class:"d-inline-block text-truncate ms-2 mb-0 h6 fw-light w-100px w-sm-200px w-md-400px"},"Lab materials")])])])])]),e("div",{class:"accordion-item mb-3"},[e("h6",{class:"accordion-header font-base",id:"heading-5"},[e("button",{class:"accordion-button fw-bold collapsed rounded d-sm-flex d-inline-block",type:"button","data-bs-toggle":"collapse","data-bs-target":"#collapse-5","aria-expanded":"false","aria-controls":"collapse-5"}," TP 2 : Détection de thèmes, LDA ")]),e("div",{id:"collapse-5",class:"accordion-collapse collapse","aria-labelledby":"heading-5","data-bs-parent":"#accordionExample2"},[e("div",{class:"accordion-body mt-3"},[e("div",{class:"d-flex justify-content-between align-items-center"},[e("div",{class:"position-relative d-flex align-items-center"},[e("a",{target:"_blank",href:"https://colab.research.google.com/github/AntoineSimoulin/m2-data-sciences/blob/master/TP2%20-%20Text%20Mining/TP2%20-%20Exploration%20de%20topics.ipynb",class:"btn btn-danger-soft btn-round btn-sm mb-0 stretched-link position-static"},[e("i",{class:"fas fa-display me-0"})]),e("span",{class:"d-inline-block text-truncate ms-2 mb-0 h6 fw-light w-100px w-sm-200px w-md-400px"},"Lab materials")])])])])]),e("div",{class:"accordion-item mb-3"},[e("h6",{class:"accordion-header font-base",id:"heading-6"},[e("button",{class:"accordion-button fw-bold collapsed rounded d-block d-sm-flex d-inline-block",type:"button","data-bs-toggle":"collapse","data-bs-target":"#collapse-6","aria-expanded":"false","aria-controls":"collapse-6"}," Cours 2 : Représentations sémantiques distributionnelles : Embeddings de mots ")]),e("div",{id:"collapse-6",class:"accordion-collapse collapse","aria-labelledby":"heading-6","data-bs-parent":"#accordionExample2"},[e("div",{class:"accordion-body mt-3"},[e("div",{class:"d-flex justify-content-between align-items-center"},[e("div",{class:"position-relative d-flex align-items-center"},[e("button",{class:"btn btn-danger-soft btn-round btn-sm mb-0 stretched-link position-static","data-bs-toggle":"modal","data-bs-target":"#lecture_2"},[e("i",{class:"fa-solid fa-file-powerpoint me-0"})]),e("span",{class:"d-inline-block text-truncate ms-2 mb-0 h6 fw-light w-100px w-sm-200px w-md-400px"},"Lecture slides")])]),e("hr"),e("div",{class:"d-flex justify-content-between align-items-center"},[e("div",{class:"position-relative d-flex align-items-center"},[e("a",{href:"#",class:"btn btn-danger-soft btn-round btn-sm mb-0 stretched-link position-static"},[e("i",{class:"fas fa-play me-0"})]),e("span",{class:"d-inline-block text-truncate ms-2 mb-0 h6 fw-light w-100px w-sm-200px w-md-400px"},"Lecture replay")])]),e("hr"),e("div",{class:"d-flex justify-content-between align-items-center"},[e("div",{class:"position-relative d-flex align-items-center"},[e("a",{target:"_blank",href:"https://colab.research.google.com/github/AntoineSimoulin/m2-data-sciences/blob/master/Cours%202%20-%20Embeddings/Words%20Embeddings.ipynb",class:"btn btn-danger-soft btn-round btn-sm mb-0 stretched-link position-static"},[e("i",{class:"fas fa-display me-0"})]),e("span",{class:"d-inline-block text-truncate ms-2 mb-0 h6 fw-light w-100px w-sm-200px w-md-400px"},"Lab materials")])])])])]),e("div",{class:"accordion-item mb-3"},[e("h6",{class:"accordion-header font-base",id:"heading-7"},[e("button",{class:"accordion-button fw-bold collapsed rounded d-sm-flex d-inline-block",type:"button","data-bs-toggle":"collapse","data-bs-target":"#collapse-7","aria-expanded":"false","aria-controls":"collapse-7"}," TP 3 : Embeddings de mots pour l'analyse de sentiments ")]),e("div",{id:"collapse-7",class:"accordion-collapse collapse","aria-labelledby":"heading-7","data-bs-parent":"#accordionExample2"},[e("div",{class:"accordion-body mt-3"},[e("div",{class:"d-flex justify-content-between align-items-center"},[e("div",{class:"position-relative d-flex align-items-center"},[e("a",{target:"_blank",href:"https://colab.research.google.com/github/AntoineSimoulin/m2-data-sciences/blob/master/TP3%20-%20Word%20Embeddings/EmojiFy.ipynb",class:"btn btn-danger-soft btn-round btn-sm mb-0 stretched-link position-static"},[e("i",{class:"fas fa-display me-0"})]),e("span",{class:"d-inline-block text-truncate ms-2 mb-0 h6 fw-light w-100px w-sm-200px w-md-400px"},"Lab materials")])])])])]),e("div",{class:"accordion-item mb-3"},[e("h6",{class:"accordion-header font-base",id:"heading-8"},[e("button",{class:"accordion-button fw-bold collapsed rounded d-sm-flex d-inline-block",type:"button","data-bs-toggle":"collapse","data-bs-target":"#collapse-8","aria-expanded":"false","aria-controls":"collapse-8"}," Cours 3 : Modélisation de séquences de mots : modèles de langue. Application à la génération de texte ")]),e("div",{id:"collapse-8",class:"accordion-collapse collapse","aria-labelledby":"heading-8","data-bs-parent":"#accordionExample2"},[e("div",{class:"accordion-body mt-3"},[e("div",{class:"d-flex justify-content-between align-items-center"},[e("div",{class:"position-relative d-flex align-items-center"},[e("button",{class:"btn btn-danger-soft btn-round btn-sm mb-0 stretched-link position-static","data-bs-toggle":"modal","data-bs-target":"#lecture_3"},[e("i",{class:"fa-solid fa-file-powerpoint me-0"})]),e("span",{class:"d-inline-block text-truncate ms-2 mb-0 h6 fw-light w-100px w-sm-200px w-md-400px"},"Lecture slides")])]),e("hr"),e("div",{class:"d-flex justify-content-between align-items-center"},[e("div",{class:"position-relative d-flex align-items-center"},[e("a",{href:"#",class:"btn btn-danger-soft btn-round btn-sm mb-0 stretched-link position-static"},[e("i",{class:"fas fa-play me-0"})]),e("span",{class:"d-inline-block text-truncate ms-2 mb-0 h6 fw-light w-100px w-sm-200px w-md-400px"},"Lecture replay")])]),e("hr"),e("div",{class:"d-flex justify-content-between align-items-center"},[e("div",{class:"position-relative d-flex align-items-center"},[e("a",{target:"_blank",href:"https://colab.research.google.com/github/AntoineSimoulin/m2-data-sciences/blob/master/Cours%203%20-%20Language%20Models/Mod%C3%A8les%20de%20langues.ipynb",class:"btn btn-danger-soft btn-round btn-sm mb-0 stretched-link position-static"},[e("i",{class:"fas fa-display me-0"})]),e("span",{class:"d-inline-block text-truncate ms-2 mb-0 h6 fw-light w-100px w-sm-200px w-md-400px"},"Lab materials")])])])])]),e("div",{class:"accordion-item mb-3"},[e("h6",{class:"accordion-header font-base",id:"heading-9"},[e("button",{class:"accordion-button fw-bold collapsed rounded d-sm-flex d-inline-block",type:"button","data-bs-toggle":"collapse","data-bs-target":"#collapse-9","aria-expanded":"false","aria-controls":"collapse-9"}," Cours 4 : Ouverture sur les méthodes de Deep Learning pour le NLP (RNN, Seq2Seq, Attention, Bert) Application au systèmes de Q&A ")]),e("div",{id:"collapse-9",class:"accordion-collapse collapse","aria-labelledby":"heading-9","data-bs-parent":"#accordionExample2"},[e("div",{class:"accordion-body mt-3"},[e("div",{class:"d-flex justify-content-between align-items-center"},[e("div",{class:"position-relative d-flex align-items-center"},[e("button",{class:"btn btn-danger-soft btn-round btn-sm mb-0 stretched-link position-static","data-bs-toggle":"modal","data-bs-target":"#lecture_4"},[e("i",{class:"fa-solid fa-file-powerpoint me-0"})]),e("span",{class:"d-inline-block text-truncate ms-2 mb-0 h6 fw-light w-100px w-sm-200px w-md-400px"},"Lecture slides")])]),e("hr"),e("div",{class:"d-flex justify-content-between align-items-center"},[e("div",{class:"position-relative d-flex align-items-center"},[e("a",{href:"#",class:"btn btn-danger-soft btn-round btn-sm mb-0 stretched-link position-static"},[e("i",{class:"fas fa-play me-0"})]),e("span",{class:"d-inline-block text-truncate ms-2 mb-0 h6 fw-light w-100px w-sm-200px w-md-400px"},"Lecture replay")])]),e("hr"),e("div",{class:"d-flex justify-content-between align-items-center"},[e("div",{class:"position-relative d-flex align-items-center"},[e("a",{target:"_blank",href:"https://colab.research.google.com/github/AntoineSimoulin/m2-data-sciences/blob/master/Cours%204%20-%20Introduction%20NLP%20%26%20Deep%20Learning/Bert_QA%5BCOLAB%5D.ipynb",class:"btn btn-danger-soft btn-round btn-sm mb-0 stretched-link position-static"},[e("i",{class:"fas fa-display me-0"})]),e("span",{class:"d-inline-block text-truncate ms-2 mb-0 h6 fw-light w-100px w-sm-200px w-md-400px"},"Lab materials")])])])])])])]),e("div",{class:"tab-pane fade",id:"course-pills-3",role:"tabpanel","aria-labelledby":"course-pills-tab-3"},[e("h5",{class:"mb-3"},"En local"),e("p",null,[a("Si vous souhaitez exécuter le TP sur votre ordinateur, voici une procédure rapide pour installer Python et les librairies requises. Ca évitera d’avoir des problèmes de version de librairies qui interfère avec d’autres cours ou projets. Pour installer Python, je vous conseille d’utiliser "),e("a",{class:"text-decoration-none text-capitalize",href:"https://www.anaconda.com/products/individual"},"Anaconda"),a(" (~450 MB). Sélectionnez l’installation correspondent à votre système d’exploitation et “64-Bit Graphical Installer” puis suivez les instructions pour installer Anaconda.")]),e("p",null,"Pour les librairies, je vous conseille de créer un environnement virtuel python pour l’ensemble du cours. Ouvrez un terminal et tapez la commande suivante : "),e("code",null,[a(" conda create -n nlp-101 python=3.6"),e("br"),a(" # Vous pouvez activer l’environnement avec la commande suivante"),e("br"),a(" conda activate nlp-101"),e("br")]),e("br"),e("p",null,[a("Si vous utilisez "),e("a",{class:"text-decoration-none text-capitalize",href:"https://jupyterlab.readthedocs.io/en/stable/"},"jupyter-lab"),a(", vous pouvez répertorier l’environement :")]),e("code",null,[a(" conda install ipykernel"),e("br"),a(" ipython kernel install --user --name='nlp-101'"),e("br")]),e("br"),e("p",null,"Nous allons installer les librairies avec le gestionnaire pip. Vérifiez que la version utilisée est bien celle associée à anaconda :"),e("code",null,[a(" pip show pip"),e("br")]),e("br"),e("p",null,"Puis mettez le à jour :"),e("code",null,[a(" pip install --upgrade pip"),e("br")]),e("br"),e("p",null,"Installez les librairies suivantes :"),e("code",null,[a(" pip install scikit-learn==0.23.2 matplotlib==3.3.2 pandas==1.1.3 lime==0.2.0.1 unidecode==1.3.2 umap-learn==0.4.6 umap-learn[plot] nltk==3.5 spacy==2.3.2"),e("br"),a(" pip install --upgrade jupyter"),e("br")]),e("br"),e("p",null,"Vous pouvez vérifier que chaque package est bien installé avec la commande : "),e("code",null,[a(' python -c "import sklearn; print(sklearn.__version__)"'),e("br")]),e("br"),e("p",null,"Finalement téléchargez le modèle Spacy français :"),e("code",null,[a(" python3 -m spacy download fr_core_news_md"),e("br")]),e("br"),e("h5",{class:"mb-3"},"Google Colab"),e("p",null,[a("Si vous disposez d'un compte Google, vous pouvez également éxécuter l'ensemble des TPs et exercices sur l'interface "),e("a",{class:"text-decoration-none text-capitalize",href:"https://colab.research.google.com/"},"Google Colab"),a(".")]),e("h5",{class:"mb-3"},"Docker"),e("p",null,"Il est également possible de faire tourner un serveur jupyter dans un Docker. L'avantage est que ce dernier tournera dans un environnement virtuel en grande partie indépendant des contraintes de votre machine. Par exemple de votre installation python ou de votre système d'exploitation."),e("p",null,[a("Pour cela, installez "),e("a",{class:"text-decoration-none text-capitalize",href:"https://www.docker.com/products/docker-desktop"},"Docker Desktop"),a(" (c'est gratuit pour les utilisation non professionnelles). Vous pouvez ensuite cloner le répertoire et construire l'image Docker. Pour cela ouvrez un terminal et exécuter les commandeds suivantes :")]),e("code",null,[a(" git clone git@github.com:AntoineSimoulin/m2-data-sciences.git"),e("br"),a(" cd m2-data-sciences"),e("br"),a(" git pull"),e("br"),a(" docker build -t m2-data-sciences ."),e("br"),a(" docker run -p 8888:8888 m2-data-sciences"),e("br")]),e("br")])])])])])])])],-1);function m(p,u,g,h,f,x){return t(),l(i,null,[o,c,d,r,b],64)}const y=s(n,[["render",m]]);export{y as default};
